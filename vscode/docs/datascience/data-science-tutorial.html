<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>data-science-tutorial</title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
    <style type="text/css">
      a.sourceLine {
        display: inline-block;
        line-height: 1.25;
      }
      a.sourceLine {
        pointer-events: none;
        color: inherit;
        text-decoration: inherit;
      }
      a.sourceLine:empty {
        height: 1.2em;
      }
      .sourceCode {
        overflow: visible;
      }
      code.sourceCode {
        white-space: pre;
        position: relative;
      }
      div.sourceCode {
        margin: 1em 0;
      }
      pre.sourceCode {
        margin: 0;
      }
      @media screen {
        div.sourceCode {
          overflow: auto;
        }
      }
      @media print {
        code.sourceCode {
          white-space: pre-wrap;
        }
        a.sourceLine {
          text-indent: -1em;
          padding-left: 1em;
        }
      }
      pre.numberSource a.sourceLine {
        position: relative;
        left: -4em;
      }
      pre.numberSource a.sourceLine::before {
        content: attr(title);
        position: relative;
        left: -1em;
        text-align: right;
        vertical-align: baseline;
        border: none;
        pointer-events: all;
        display: inline-block;
        -webkit-touch-callout: none;
        -webkit-user-select: none;
        -khtml-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
        padding: 0 4px;
        width: 4em;
        color: #aaaaaa;
      }
      pre.numberSource {
        margin-left: 3em;
        border-left: 1px solid #aaaaaa;
        padding-left: 4px;
      }
      div.sourceCode {
      }
      @media screen {
        a.sourceLine::before {
          text-decoration: underline;
        }
      }
      code span.al {
        color: #ff0000;
        font-weight: bold;
      } /* Alert */
      code span.an {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Annotation */
      code span.at {
        color: #7d9029;
      } /* Attribute */
      code span.bn {
        color: #40a070;
      } /* BaseN */
      code span.bu {
      } /* BuiltIn */
      code span.cf {
        color: #007020;
        font-weight: bold;
      } /* ControlFlow */
      code span.ch {
        color: #4070a0;
      } /* Char */
      code span.cn {
        color: #880000;
      } /* Constant */
      code span.co {
        color: #60a0b0;
        font-style: italic;
      } /* Comment */
      code span.cv {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* CommentVar */
      code span.do {
        color: #ba2121;
        font-style: italic;
      } /* Documentation */
      code span.dt {
        color: #902000;
      } /* DataType */
      code span.dv {
        color: #40a070;
      } /* DecVal */
      code span.er {
        color: #ff0000;
        font-weight: bold;
      } /* Error */
      code span.ex {
      } /* Extension */
      code span.fl {
        color: #40a070;
      } /* Float */
      code span.fu {
        color: #06287e;
      } /* Function */
      code span.im {
      } /* Import */
      code span.in {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Information */
      code span.kw {
        color: #007020;
        font-weight: bold;
      } /* Keyword */
      code span.op {
        color: #666666;
      } /* Operator */
      code span.ot {
        color: #007020;
      } /* Other */
      code span.pp {
        color: #bc7a00;
      } /* Preprocessor */
      code span.sc {
        color: #4070a0;
      } /* SpecialChar */
      code span.ss {
        color: #bb6688;
      } /* SpecialString */
      code span.st {
        color: #4070a0;
      } /* String */
      code span.va {
        color: #19177c;
      } /* Variable */
      code span.vs {
        color: #4070a0;
      } /* VerbatimString */
      code span.wa {
        color: #60a0b0;
        font-weight: bold;
        font-style: italic;
      } /* Warning */
    </style>
  </head>
  <body>
    <h1 id="data-science-in-vs-code-tutorial">
      Data Science in VS Code tutorial
    </h1>
    <p>
      This tutorial demonstrates using Visual Studio Code and the Microsoft
      Python extension with common data science libraries to explore a basic
      data science scenario. Specifically, using passenger data from the
      Titanic, you will learn how to set up a data science environment, import
      and clean data, create a machine learning model for predicting survival on
      the Titanic, and evaluate the accuracy of the generated model.
    </p>
    <h2 id="prerequisites">Prerequisites</h2>
    <p>
      The following installations are required for the completion of the
      tutorial. If you do not have them already, install them prior to
      beginning.
    </p>
    <ul>
      <li><a href="https://code.visualstudio.com/">Visual Studio Code</a></li>
      <li>
        <p>
          The
          <a
            href="https://marketplace.visualstudio.com/items?itemName=ms-python.python"
            >Python extension for VS Code</a
          >
          from the Visual Studio Marketplace. For additional details on
          installing extensions, see
          <a href="/docs/editor/extension-gallery.md">Extension Marketplace</a>.
          The Python extension is named <strong>Python</strong> and published by
          Microsoft.
        </p>
        <p>
          <a
            href="https://marketplace.visualstudio.com/items?itemName=ms-python.python"
            ><img
              src="images/data-science-tutorial/python-extension-marketplace.png"
              alt="Python extension on Marketplace"
          /></a>
        </p>
      </li>
      <li>
        <p>
          <a href="https://docs.conda.io/en/latest/miniconda.html"
            >Miniconda with Python 3.7</a
          >
        </p>
        <blockquote>
          <p>
            <strong>Note</strong>: If you already have the full Anaconda
            distribution installed, you don’t need to install Miniconda.
            Alternatively, if you’d prefer not to use Anaconda or Miniconda, you
            can create a Python virtual environment and install the packages
            needed for the tutorial using pip. If you go this route, you will
            need to install the following packages: pandas, jupyter, seaborn,
            scikit-learn, keras, and tensorflow.
          </p>
        </blockquote>
      </li>
    </ul>
    <h2 id="set-up-a-data-science-environment">
      Set up a data science environment
    </h2>
    <p>
      Visual Studio Code and the Python extension provide a great editor for
      data science scenarios. With native support for Jupyter notebooks combined
      with Anaconda, it’s easy to get started. In this section, you will create
      a workspace for the tutorial, create an Anaconda environment with the data
      science modules needed for the tutorial, and create a Jupyter notebook
      that you’ll use for creating a machine learning model.
    </p>
    <ol type="1">
      <li>
        Begin by creating an Anaconda environment for the data science tutorial.
        Open an Anaconda command prompt and run
        <code
          >conda create -n myenv python=3.7 pandas jupyter seaborn scikit-learn
          keras tensorflow</code
        >
        to create an environment named <strong>myenv</strong>. For additional
        information about creating and managing Anaconda environments, see the
        <a
          href="https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html"
          >Anaconda documentation</a
        >.
      </li>
      <li>
        Next, create a folder in a convenient location to serve as your VS Code
        workspace for the tutorial, name it <code>hello_ds</code>.
      </li>
      <li>
        Open the project folder in VS Code by running VS Code and using the
        <strong>File</strong> &gt; <strong>Open Folder</strong> command.
      </li>
      <li>
        <p>
          Once VS Code launches, open the Command Palette (<strong>View</strong>
          &gt; <strong>Command Palette</strong> or
          <code>kb(workbench.action.showCommands)</code>). Then select the
          <strong>Python: Select Interpreter</strong> command:
        </p>
        <figure>
          <img
            src="images/shared/command-palette.png"
            alt="Data Science tutorial: opening the Command Palette in VS Code"
          />
          <figcaption>
            Data Science tutorial: opening the Command Palette in VS Code
          </figcaption>
        </figure>
      </li>
      <li>
        <p>
          The <strong>Python: Select Interpreter</strong> command presents the
          list of available interpreters that VS Code was able to locate
          automatically (your list will vary from the one shown below; if you
          don’t see the desired interpreter see
          <a href="/docs/python/environments.md"
            >Configuring Python environments</a
          >). From the list, select the Anaconda environment you created, which
          should include the text <strong>‘myenv’: conda</strong>.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/anaconda-environment.png"
            alt="Selecting a python environment"
          />
          <figcaption>Selecting a python environment</figcaption>
        </figure>
      </li>
      <li>
        <p>
          With the environment and VS Code setup, the final step is to create
          the Jupyter notebook that will be used for the tutorial. Open the
          Command Palette (<code>kb(workbench.action.showCommands)</code>) and
          select <strong>Jupyter: Create New Blank Jupyter Notebook</strong>.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/create-notebook.png"
            alt="Creating a new Jupyter Notebook"
          />
          <figcaption>Creating a new Jupyter Notebook</figcaption>
        </figure>
        <blockquote>
          <p>
            <strong>Note</strong>: Alternatively, from the VS Code File
            Explorer, you can use the New File icon to create a Notebook file
            named <code>hello.ipynb</code>.
          </p>
        </blockquote>
      </li>
      <li>
        <p>
          Use the Save icon on the main notebook toolbar to save the notebook
          with the filename <code>hello</code>.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/notebook-save.png"
            alt="Saving a Jupyter Notebook"
          />
          <figcaption>Saving a Jupyter Notebook</figcaption>
        </figure>
      </li>
      <li>
        <p>
          After your file is created, you should see the open
          <a href="https://jupyter.org/">Jupyter notebook</a> in the native
          notebook editor. For additional information about native Jupyter
          notebook support, see
          <a href="/docs/datascience/jupyter-notebooks.md">this section</a> of
          the documentation.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/notebook-editor.png"
            alt="Viewing a new Jupyter Notebook"
          />
          <figcaption>Viewing a new Jupyter Notebook</figcaption>
        </figure>
      </li>
    </ol>
    <h2 id="prepare-the-data">Prepare the data</h2>
    <p>
      This tutorial uses the
      <a
        href="http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.html"
        >Titanic dataset</a
      >
      available on <a href="https://www.openml.org/d/40945">OpenML.org</a>,
      which is obtained from Vanderbilt University’s Department of Biostatistics
      at
      <a href="http://biostat.mc.vanderbilt.edu/DataSets"
        >http://biostat.mc.vanderbilt.edu/DataSets</a
      >. The Titanic data provides information about the survival of passengers
      on the Titanic, as well as characteristics about the passengers such as
      age and ticket class. Using this data, the tutorial will establish a model
      for predicting whether a given passenger would have survived the sinking
      of the Titanic. This section shows how to load and manipulate data in your
      Jupyter notebook.
    </p>
    <ol type="1">
      <li>
        To begin, download the Titanic data from
        <a href="https://www.openml.org/d/40945">OpenML.org</a> as a csv file
        named <code>data.csv</code> and save it to the
        <code>hello_ds</code> folder that you created in the previous section.
      </li>
      <li>
        In VS Code, open the <code>hello_ds</code> folder and the Jupyter
        notebook (<code>hello.ipynb</code>), by going to
        <strong>File</strong> &gt; <strong>Open Folder</strong>.
      </li>
      <li>
        <p>
          Within your Jupyter notebook begin by importing the
          <a href="https://pandas.pydata.org/">pandas</a> and
          <a href="https://numpy.org/">numpy</a> libraries, two common libraries
          used for manipulating data, and loading the Titanic data into a pandas
          <a
            href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
            >DataFrame</a
          >. To do so, copy the below code into the first cell of the notebook.
          For additional guidance about working with Jupyter notebooks in VS
          Code, see the
          <a href="/docs/datascience/jupyter-notebooks.md"
            >Working with Jupyter Notebooks</a
          >
          documentation.
        </p>
        <div class="sourceCode" id="cb1">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb1-1" title="1"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb1-2" title="2"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb1-3" title="3">data <span class="op">=</span> pd.read_csv(<span class="st">&#39;data.csv&#39;</span>)</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          Now, run the cell using the Run cell icon or the
          <code>kbstyle(Shift+Enter)</code> shortcut.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-01.png"
            alt="Running a Jupyter notebook cell"
          />
          <figcaption>Running a Jupyter notebook cell</figcaption>
        </figure>
      </li>
      <li>
        <p>
          After the cell finishes running, you can view the data that was loaded
          using the variable explorer and data viewer. First click on the chart
          icon in the notebook’s upper toolbar, then the data viewer icon to the
          right of the <code>data</code> variable. For additional information
          about the data set, refer to
          <a
            href="http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic3info.txt"
            >this document</a
          >
          about how it was constructed.
        </p>
        <figure>
          <img
            src="images/data-science-tutorial/variable-explorer.png"
            alt="Data viewer and variable explorer"
          />
          <figcaption>Data viewer and variable explorer</figcaption>
        </figure>
        <p>
          You can then use the data viewer to view, sort, and filter the rows of
          data. After reviewing the data, it can then be helpful to graph some
          aspects of it to help visualize the relationships between the
          different variables.
        </p>
      </li>
      <li>
        <p>
          Before the data can be graphed though, you need to make sure that
          there aren’t any issues with it. If you look at the Titanic csv file,
          one thing you’ll notice is that a question mark (“?”) was used to
          designate cells where data wasn’t available.
        </p>
        <p>
          While Pandas can read this value into a DataFrame, the result for a
          column like Age is that its data type will be set to Object instead of
          a numeric data type, which is problematic for graphing.
        </p>
        <p>
          This problem can be corrected by replacing the question mark with a
          missing value that pandas is able to understand. Add the following
          code to the next cell in your notebook to replace the question marks
          in the <strong>age</strong> and <strong>fare</strong> columns with the
          <a
            href="https://docs.scipy.org/doc/numpy/reference/constants.html?highlight=nan#numpy.nan"
            >numpy NaN</a
          >
          value. Notice that we also need to update the column’s data type after
          replacing the values.
        </p>
        <blockquote>
          <p>
            <strong>Tip</strong>: To add a new cell you can use the insert cell
            icon that’s in the bottom left corner of an existing cell.
            Alternatively, you can also use the <code>kbstyle(Esc)</code> to
            enter command mode, followed by the <code>kbstyle(B)</code> key.
          </p>
        </blockquote>
        <div class="sourceCode" id="cb2">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb2-1" title="1">data.replace(<span class="st">&#39;?&#39;</span>, np.nan, inplace<span class="op">=</span> <span class="va">True</span>)</a>
<a class="sourceLine" id="cb2-2" title="2">data <span class="op">=</span> data.astype({<span class="st">&quot;age&quot;</span>: np.float64, <span class="st">&quot;fare&quot;</span>: np.float64})</a></code></pre>
        </div>
        <blockquote>
          <p>
            <strong>Note</strong>: If you ever need to see the data type that
            has been used for a column, you can use the
            <a
              href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html#pandas.DataFrame.dtypes"
              >DataFrame dtypes</a
            >
            attribute.
          </p>
        </blockquote>
      </li>
      <li>
        <p>
          Now that the data is in good shape, you can use
          <a href="https://seaborn.pydata.org/">seaborn</a> and
          <a href="https://matplotlib.org">matplotlib</a> to view how certain
          columns of the dataset relate to survivability. Add the following code
          to the next cell in your notebook and run it to see the generated
          plots.
        </p>
        <div class="sourceCode" id="cb3">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb3-1" title="1"><span class="im">import</span> seaborn <span class="im">as</span> sns</a>
<a class="sourceLine" id="cb3-2" title="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb3-3" title="3"></a>
<a class="sourceLine" id="cb3-4" title="4">fig, axs <span class="op">=</span> plt.subplots(ncols<span class="op">=</span><span class="dv">5</span>, figsize<span class="op">=</span>(<span class="dv">30</span>,<span class="dv">5</span>))</a>
<a class="sourceLine" id="cb3-5" title="5">sns.violinplot(x<span class="op">=</span><span class="st">&quot;survived&quot;</span>, y<span class="op">=</span><span class="st">&quot;age&quot;</span>, hue<span class="op">=</span><span class="st">&quot;sex&quot;</span>, data<span class="op">=</span>data, ax<span class="op">=</span>axs[<span class="dv">0</span>])</a>
<a class="sourceLine" id="cb3-6" title="6">sns.pointplot(x<span class="op">=</span><span class="st">&quot;sibsp&quot;</span>, y<span class="op">=</span><span class="st">&quot;survived&quot;</span>, hue<span class="op">=</span><span class="st">&quot;sex&quot;</span>, data<span class="op">=</span>data, ax<span class="op">=</span>axs[<span class="dv">1</span>])</a>
<a class="sourceLine" id="cb3-7" title="7">sns.pointplot(x<span class="op">=</span><span class="st">&quot;parch&quot;</span>, y<span class="op">=</span><span class="st">&quot;survived&quot;</span>, hue<span class="op">=</span><span class="st">&quot;sex&quot;</span>, data<span class="op">=</span>data, ax<span class="op">=</span>axs[<span class="dv">2</span>])</a>
<a class="sourceLine" id="cb3-8" title="8">sns.pointplot(x<span class="op">=</span><span class="st">&quot;pclass&quot;</span>, y<span class="op">=</span><span class="st">&quot;survived&quot;</span>, hue<span class="op">=</span><span class="st">&quot;sex&quot;</span>, data<span class="op">=</span>data, ax<span class="op">=</span>axs[<span class="dv">3</span>])</a>
<a class="sourceLine" id="cb3-9" title="9">sns.violinplot(x<span class="op">=</span><span class="st">&quot;survived&quot;</span>, y<span class="op">=</span><span class="st">&quot;fare&quot;</span>, hue<span class="op">=</span><span class="st">&quot;sex&quot;</span>, data<span class="op">=</span>data, ax<span class="op">=</span>axs[<span class="dv">4</span>])</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-02.png"
            alt="Graphing the titanic data"
          />
          <figcaption>Graphing the titanic data</figcaption>
        </figure>
        <blockquote>
          <p>
            <strong>Note</strong>: To better view details on the graphs, you can
            open them in plot viewer by hovering over the upper left corner of
            the graph and clicking the button that appears.
          </p>
        </blockquote>
      </li>
      <li>
        <p>
          These graphs are helpful in seeing some of the relationships between
          survival and the input variables of the data, but it’s also possible
          to use <strong>pandas</strong> to calculate correlations. To do so,
          all the variables used need to be numeric for the correlation
          calculation and currently gender is stored as a string. To convert
          those string values to integers, add and run the following code.
        </p>
        <div class="sourceCode" id="cb4">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb4-1" title="1">data.replace({<span class="st">&#39;male&#39;</span>: <span class="dv">1</span>, <span class="st">&#39;female&#39;</span>: <span class="dv">0</span>}, inplace<span class="op">=</span><span class="va">True</span>)</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          Now, you can analyze the correlation between all the input variables
          to identify the features that would be the best inputs to a machine
          learning model. The closer a value is to 1, the higher the correlation
          between the value and the result. Use the following code to correlate
          the relationship between all variables and survival.
        </p>
        <div class="sourceCode" id="cb5">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb5-1" title="1">data.corr().<span class="bu">abs</span>()[[<span class="st">&quot;survived&quot;</span>]]</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-03.png"
            alt="Determining the correlation between input variables and survival"
          />
          <figcaption>
            Determining the correlation between input variables and survival
          </figcaption>
        </figure>
      </li>
      <li>
        <p>
          Looking at the correlation results, you’ll notice that some variables
          like gender have a fairly high correlation to survival, while others
          like relatives (sibsp = siblings or spouse, parch = parents or
          children) seem to have little correlation.
        </p>
        <p>
          Let’s hypothesize that <strong>sibsp</strong> and
          <strong>parch</strong> are related in how they affect survivability,
          and group them into a new column called “relatives” to see whether the
          combination of them has a higher correlation to survivability. To do
          this, you will check if for a given passenger, the number of
          <strong>sibsp</strong> and <strong>parch</strong> is greater than 0
          and, if so, you can then say that they had a relative on board.
        </p>
        <p>
          Use the following code to create a new variable and column in the
          dataset called <code>relatives</code> and check the correlation again.
        </p>
        <div class="sourceCode" id="cb6">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb6-1" title="1">data[<span class="st">&#39;relatives&#39;</span>] <span class="op">=</span> data.<span class="bu">apply</span> (<span class="kw">lambda</span> row: <span class="bu">int</span>((row[<span class="st">&#39;sibsp&#39;</span>] <span class="op">+</span> row[<span class="st">&#39;parch&#39;</span>]) <span class="op">&gt;</span> <span class="dv">0</span>), axis<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb6-2" title="2">data.corr().<span class="bu">abs</span>()[[<span class="st">&quot;survived&quot;</span>]]</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-04.png"
            alt="Determining the correlation between having relatives and survival"
          />
          <figcaption>
            Determining the correlation between having relatives and survival
          </figcaption>
        </figure>
      </li>
      <li>
        <p>
          You’ll notice that in fact when looked at from the standpoint of
          whether a person had relatives, versus how many relatives, there is a
          higher correlation with survival. With this information in hand, you
          can now drop from the dataset the low value <strong>sibsp</strong> and
          <strong>parch</strong> columns, as well as any rows that had
          <strong>NaN</strong> values, to end up with a dataset that can be used
          for training a model.
        </p>
        <div class="sourceCode" id="cb7">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb7-1" title="1">data <span class="op">=</span> data[[<span class="st">&#39;sex&#39;</span>, <span class="st">&#39;pclass&#39;</span>,<span class="st">&#39;age&#39;</span>,<span class="st">&#39;relatives&#39;</span>,<span class="st">&#39;fare&#39;</span>,<span class="st">&#39;survived&#39;</span>]].dropna()</a></code></pre>
        </div>
        <blockquote>
          <p>
            <strong>Note</strong>: Although age had a low direct correlation, it
            was kept because it seems reasonable that it might still have
            correlation in conjunction with other inputs.
          </p>
        </blockquote>
      </li>
    </ol>
    <h2 id="train-and-evaluate-a-model">Train and evaluate a model</h2>
    <p>
      With the dataset ready, you can now begin creating a model. For this
      section you’ll use the
      <a href="https://scikit-learn.org/stable/">scikit-learn</a> library (as it
      offers some useful helper functions) to do pre-processing of the dataset,
      train a classification model to determine survivability on the Titanic,
      and then use that model with test data to determine its accuracy.
    </p>
    <ol type="1">
      <li>
        <p>
          A common first step to training a model is to divide up the dataset
          into training and validation data. This allows you to use a portion of
          the data to train the model and a portion of the data to test the
          model. If you used all your data to train the model, you wouldn’t have
          a way to estimate how well it would actually perform against data the
          model has not yet seen. A benefit of the scikit-learn library is that
          it provides a method specifically for splitting a dataset into
          training and test data.
        </p>
        <p>
          Add and run a cell with the following code to the notebook to split up
          the data.
        </p>
        <div class="sourceCode" id="cb8">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb8-1" title="1"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</a>
<a class="sourceLine" id="cb8-2" title="2">x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(data[[<span class="st">&#39;sex&#39;</span>,<span class="st">&#39;pclass&#39;</span>,<span class="st">&#39;age&#39;</span>,<span class="st">&#39;relatives&#39;</span>,<span class="st">&#39;fare&#39;</span>]], data.survived, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          Next, you’ll normalize the inputs such that all features are treated
          equally. For example, within the dataset the values for age range from
          ~0-100, while gender is only a 1 or 0. By normalizing all the
          variables, you can ensure that the ranges of values are all the same.
          Use the following code in a new code cell to scale the input values.
        </p>
        <div class="sourceCode" id="cb9">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb9-1" title="1"><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</a>
<a class="sourceLine" id="cb9-2" title="2">sc <span class="op">=</span> StandardScaler()</a>
<a class="sourceLine" id="cb9-3" title="3">X_train <span class="op">=</span> sc.fit_transform(x_train)</a>
<a class="sourceLine" id="cb9-4" title="4">X_test <span class="op">=</span> sc.transform(x_test)</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          There are a number of different machine learning algorithms that you
          could choose from to model the data and scikit-learn provides support
          for a number of
          <a href="https://scikit-learn.org/stable/user_guide.html">them</a>, as
          well as a
          <a
            href="https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
            >chart</a
          >
          to help select the one that’s right for your scenario. For now, use
          the
          <a href="https://scikit-learn.org/stable/modules/naive_bayes.html"
            >Naïve Bayes algorithm</a
          >, a common algorithm for classification problems. Add a cell with the
          following code to create and train the algorithm.
        </p>
        <div class="sourceCode" id="cb10">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb10-1" title="1"><span class="im">from</span> sklearn.naive_bayes <span class="im">import</span> GaussianNB</a>
<a class="sourceLine" id="cb10-2" title="2">model <span class="op">=</span> GaussianNB()</a>
<a class="sourceLine" id="cb10-3" title="3">model.fit(X_train, y_train)</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          With a trained model, you can now try it against the test data set
          that was held back from training. Add and run the following code to
          predict the outcome of the test data and calculate the accuracy of the
          model.
        </p>
        <div class="sourceCode" id="cb11">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb11-1" title="1"><span class="im">from</span> sklearn <span class="im">import</span> metrics</a>
<a class="sourceLine" id="cb11-2" title="2">predict_test <span class="op">=</span> model.predict(X_test)</a>
<a class="sourceLine" id="cb11-3" title="3"><span class="bu">print</span>(metrics.accuracy_score(y_test, predict_test))</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-05.png"
            alt="Running the trained model against test data"
          />
          <figcaption>Running the trained model against test data</figcaption>
        </figure>
        <p>
          Looking at the result of the test data, you’ll see that the trained
          algorithm had a ~75% success rate at estimating survival.
        </p>
      </li>
    </ol>
    <h2 id="optional-use-a-neural-network-to-increase-accuracy">
      (Optional) Use a neural network to increase accuracy
    </h2>
    <p>
      A neural network is a model that uses weights and activation functions,
      modeling aspects of human neurons, to determine an outcome based on
      provided inputs. Unlike the machine learning algorithm you looked at
      previously, neural networks are a form of deep learning wherein you don’t
      need to know an ideal algorithm for your problem set ahead of time. It can
      be used for many different scenarios and classification is one of them.
      For this section, you’ll use the
      <a href="https://keras.io/">Keras</a> library with
      <a href="https://www.tensorflow.org/">TensorFlow</a> to construct the
      neural network, and explore how it handles the Titanic dataset.
    </p>
    <ol type="1">
      <li>
        <p>
          The first step is to import the required libraries and to create the
          model. In this case, you’ll use a
          <a href="https://keras.io/getting-started/sequential-model-guide/"
            >Sequential</a
          >
          neural network, which is a layered neural network wherein there are
          multiple layers that feed into each other in sequence.
        </p>
        <div class="sourceCode" id="cb12">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb12-1" title="1"><span class="im">from</span> keras.models <span class="im">import</span> Sequential</a>
<a class="sourceLine" id="cb12-2" title="2"><span class="im">from</span> keras.layers <span class="im">import</span> Dense</a>
<a class="sourceLine" id="cb12-3" title="3"></a>
<a class="sourceLine" id="cb12-4" title="4">model <span class="op">=</span> Sequential()</a></code></pre>
        </div>
      </li>
      <li>
        <p>
          After defining the model, the next step is to add the layers of the
          neural network. For now, let’s keep things simple and just use three
          layers. Add the following code to create the layers of the neural
          network.
        </p>
        <div class="sourceCode" id="cb13">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb13-1" title="1">model.add(Dense(<span class="dv">5</span>, kernel_initializer <span class="op">=</span> <span class="st">&#39;uniform&#39;</span>, activation <span class="op">=</span> <span class="st">&#39;relu&#39;</span>, input_dim <span class="op">=</span> <span class="dv">5</span>))</a>
<a class="sourceLine" id="cb13-2" title="2">model.add(Dense(<span class="dv">5</span>, kernel_initializer <span class="op">=</span> <span class="st">&#39;uniform&#39;</span>, activation <span class="op">=</span> <span class="st">&#39;relu&#39;</span>))</a>
<a class="sourceLine" id="cb13-3" title="3">model.add(Dense(<span class="dv">1</span>, kernel_initializer <span class="op">=</span> <span class="st">&#39;uniform&#39;</span>, activation <span class="op">=</span> <span class="st">&#39;sigmoid&#39;</span>))</a></code></pre>
        </div>
        <ul>
          <li>
            The first layer will be set to have a dimension of 5, since you have
            5 inputs: sex, pclass, age, relatives, and fare.
          </li>
          <li>
            The last layer must output 1, since you want a 1-dimensional output
            indicating whether a passenger would survive.
          </li>
          <li>
            The middle layer was kept at 5 for simplicity, although that value
            could have been different.
          </li>
        </ul>
        <p>
          The rectified linear unit (relu) activation function is used as a good
          general activation function for the first two layers, while the
          sigmoid activation function is required for the final layer as the
          output you want (of whether a passenger survives or not) needs to be
          scaled in the range of 0-1 (the probability of a passenger surviving).
        </p>
        <p>
          You can also look at the summary of the model you built with this line
          of code:
        </p>
        <div class="sourceCode" id="cb14">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb14-1" title="1">model.summary()</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-06.png"
            alt="Viewing a summary of the sequential neural network"
          />
          <figcaption>
            Viewing a summary of the sequential neural network
          </figcaption>
        </figure>
      </li>
      <li>
        <p>
          Once the model is created, it needs to be compiled. As part of this,
          you need to define what type of optimizer will be used, how loss will
          be calculated, and what metric should be optimized for. Add the
          following code to build and train the model. You’ll notice that after
          training the accuracy is ~80%.
        </p>
        <blockquote>
          <p>
            <strong>Note</strong>: This step may take anywhere from a few
            seconds to a few minutes to run depending on your machine.
          </p>
        </blockquote>
        <div class="sourceCode" id="cb15">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb15-1" title="1">model.<span class="bu">compile</span>(optimizer<span class="op">=</span><span class="st">&quot;adam&quot;</span>, loss<span class="op">=</span><span class="st">&#39;binary_crossentropy&#39;</span>, metrics<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>])</a>
<a class="sourceLine" id="cb15-2" title="2">model.fit(X_train, y_train, batch_size<span class="op">=</span><span class="dv">32</span>, epochs<span class="op">=</span><span class="dv">50</span>)</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-07.png"
            alt="Build and train the neural network"
          />
          <figcaption>Build and train the neural network</figcaption>
        </figure>
      </li>
      <li>
        <p>
          With the model built and trained its now time to see how it performs
          against the test data.
        </p>
        <div class="sourceCode" id="cb16">
          <pre
            class="sourceCode python"
          ><code class="sourceCode python"><a class="sourceLine" id="cb16-1" title="1">y_pred <span class="op">=</span> model.predict_classes(X_test)</a>
<a class="sourceLine" id="cb16-2" title="2"><span class="bu">print</span>(metrics.accuracy_score(y_test, y_pred))</a></code></pre>
        </div>
        <figure>
          <img
            src="images/data-science-tutorial/jupyter-cell-08.png"
            alt="Evaluate the neural network"
          />
          <figcaption>Evaluate the neural network</figcaption>
        </figure>
        <p>
          Similar to the training, you’ll notice that you were able to get close
          to 80% accuracy in predicting survival of passengers. This result was
          better than the 75% accuracy from the Naive Bayes Classifier tried
          previously.
        </p>
      </li>
    </ol>
    <h2 id="next-steps">Next steps</h2>
    <p>
      Now that you’re familiar with the basics of performing machine learning
      within Visual Studio Code, here are some other Microsoft resources and
      tutorials to check out.
    </p>
    <ul>
      <li>
        Learn more about working with
        <a href="https://youtu.be/FSdIoJdSnig"
          >Jupyter Notebooks in Visual Studio Code</a
        >
        (video).
      </li>
      <li>
        <a
          href="https://docs.microsoft.com/azure/machine-learning/service/how-to-vscode-tools"
          >Get started with Azure Machine Learning for VS Code</a
        >
        to deploy and optimize your model using the power of Azure.
      </li>
      <li>
        Find additional data to explore on
        <a href="https://azure.microsoft.com/services/open-datasets/"
          >Azure Open Data Sets</a
        >.
      </li>
    </ul>
  </body>
</html>
