<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <meta charset="utf-8" />
    <meta name="generator" content="pandoc" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=yes"
    />
    <title>Use autograding</title>
    <style type="text/css">
      code {
        white-space: pre-wrap;
      }
      span.smallcaps {
        font-variant: small-caps;
      }
      span.underline {
        text-decoration: underline;
      }
      div.column {
        display: inline-block;
        vertical-align: top;
        width: 50%;
      }
    </style>
  </head>
  <body>
    <header id="title-block-header">
      <h1 class="title">Use autograding</h1>
    </header>
    <h2 id="about-autograding">About autograding</h2>
    <p>{% data reusables.classroom.about-autograding %}</p>
    <p>
      After a student accepts an assignment, on every push to the assignment
      repository, {% data variables.product.prodname_actions %} runs the
      commands for your autograding test in a Linux environment containing the
      student’s newest code. {% data variables.product.prodname_classroom %}
      creates the necessary workflows for {% data
      variables.product.prodname_actions %}. You don’t need experience with {%
      data variables.product.prodname_actions %} to use autograding.
    </p>
    <p>
      You can use a testing framework, run a custom command, write input/output
      tests, or combine different testing methods. The Linux environment for
      autograding contains many popular software tools. For more information,
      see the details for the latest version of Ubuntu in “<a
        href="/actions/reference/specifications-for-github-hosted-runners#supported-software"
        >Specifications for {% data variables.product.company_short %}-hosted
        runners</a
      >.”
    </p>
    <p>
      You can see an overview of which students are passing autograding tests by
      navigating to the assignment in {% data
      variables.product.prodname_classroom %}. A green checkmark means that all
      tests are passing for the student, and a red X means that some or all
      tests are failing for the student. If you award points for one or more
      tests, then a bubble shows the score for the tests out of the maximum
      possible score for the assignment.
    </p>
    <figure>
      <img
        src="/assets/images/help/classroom/autograding-hero.png"
        alt="Overview for an assignment with autograding results"
      />
      <figcaption>
        Overview for an assignment with autograding results
      </figcaption>
    </figure>
    <h2 id="grading-methods">Grading methods</h2>
    <p>
      There are two grading methods: input/output tests and run command tests.
    </p>
    <h3 id="inputoutput-test">Input/output test</h3>
    <p>
      An input/output test optionally runs a setup command, then provides
      standard input to a test command. {% data
      variables.product.prodname_classroom %} evaluates the test command’s
      output against an expected result.
    </p>
    <table>
      <colgroup>
        <col style="width: 50%" />
        <col style="width: 50%" />
      </colgroup>
      <thead>
        <tr class="header">
          <th style="text-align: left">Setting</th>
          <th style="text-align: left">Description</th>
        </tr>
      </thead>
      <tbody>
        <tr class="odd">
          <td style="text-align: left"><strong>Test name</strong></td>
          <td style="text-align: left">
            The name of the test, to identify the test in logs
          </td>
        </tr>
        <tr class="even">
          <td style="text-align: left"><strong>Setup command</strong></td>
          <td style="text-align: left">
            <em>Optional</em>. A command to run before tests, such as
            compilation or installation
          </td>
        </tr>
        <tr class="odd">
          <td style="text-align: left"><strong>Run command</strong></td>
          <td style="text-align: left">
            The command to run the test and generate standard output for
            evaluation
          </td>
        </tr>
        <tr class="even">
          <td style="text-align: left"><strong>Inputs</strong></td>
          <td style="text-align: left">Standard input for run command</td>
        </tr>
        <tr class="odd">
          <td style="text-align: left"><strong>Expected output</strong></td>
          <td style="text-align: left">
            The output that you want to see as standard output from the run
            command
          </td>
        </tr>
      </tbody>
    </table>
    | <strong>Comparison</strong> | The type of comparison between the run
    command’s output and the expected output<br /><br />
    <ul>
      <li>
        <strong>Included</strong>: Passes when the expected output appears<br />anywhere
        in the standard output from the run command
      </li>
      <li>
        <strong>Exact</strong>: Passes when the expected output is completely
        identical<br />to the standard output from the run command
      </li>
      <li>
        <strong>Regex</strong>: Passes if the regular expression in expected<br />output
        matches against the standard output from the run command
      </li>
    </ul>
    <p>
      | | <strong>Timeout</strong> | In minutes, how long a test should run
      before resulting in failure | | <strong>Points</strong> |
      <em>Optional</em>. The number of points the test is worth toward a total
      score |
    </p>
    <h3 id="run-command-test">Run command test</h3>
    <p>
      A run command test runs a setup command, then runs a test command. {% data
      variables.product.prodname_classroom %} checks the exit status of the test
      command. An exit code of <code>0</code> results in success, and any other
      exit code results in failure.
    </p>
    <p>
      {% data variables.product.prodname_classroom %} provides presets for
      language-specific run command tests for a variety of programming
      languages. For example, the <strong>Run node</strong> test prefills the
      setup command with <code>npm install</code> and the test command with
      <code>npm test</code>.
    </p>
    <table>
      <colgroup>
        <col style="width: 50%" />
        <col style="width: 50%" />
      </colgroup>
      <thead>
        <tr class="header">
          <th style="text-align: left">Setting</th>
          <th style="text-align: left">Description</th>
        </tr>
      </thead>
      <tbody>
        <tr class="odd">
          <td style="text-align: left"><strong>Test name</strong></td>
          <td style="text-align: left">
            The name of the test, to identify the test in logs
          </td>
        </tr>
        <tr class="even">
          <td style="text-align: left"><strong>Setup command</strong></td>
          <td style="text-align: left">
            <em>Optional</em>. A command to run before tests, such as
            compilation or installation
          </td>
        </tr>
        <tr class="odd">
          <td style="text-align: left"><strong>Run command</strong></td>
          <td style="text-align: left">
            The command to run the test and generate an exit code for evaluation
          </td>
        </tr>
        <tr class="even">
          <td style="text-align: left"><strong>Timeout</strong></td>
          <td style="text-align: left">
            In minutes, how long a test should run before resulting in failure
          </td>
        </tr>
        <tr class="odd">
          <td style="text-align: left"><strong>Points</strong></td>
          <td style="text-align: left">
            <em>Optional</em>. The number of points the test is worth toward a
            total score
          </td>
        </tr>
      </tbody>
    </table>
    <h2 id="configuring-autograding-tests-for-an-assignment">
      Configuring autograding tests for an assignment
    </h2>
    <p>
      You can add autograding tests during the creation of a new assignment. {%
      data reusables.classroom.for-more-information-about-assignment-creation %}
    </p>
    <p>
      You can add, edit, or delete autograding tests for an existing assignment.
      If you change the autograding tests for an existing assignment, existing
      assignment repositories will not be affected. A student or team must
      accept the assignment and create a new assignment repository to use the
      new tests.
    </p>
    <p>
      {% data reusables.classroom.sign-into-github-classroom %} {% data
      reusables.classroom.click-classroom-in-list %} {% data
      reusables.classroom.assignments-click-pencil %} 1. In the left sidebar,
      click <strong>Grading and feedback</strong>.
      <img
        src="/assets/images/help/classroom/assignments-click-grading-and-feedback.png"
        alt="“Grading and feedback” to the left of assignment’s basics"
      />
      1. Add, edit, or delete an autograding test. - To add a test, under “Add
      autograding tests”, select the <strong>Add test</strong> drop-down menu,
      then click the grading method you want to use.
      <img
        src="/assets/images/help/classroom/autograding-click-grading-method.png"
        alt="Using the “Add test” drop-down menu to click a grading method"
      />
      Configure the test, then click <strong>Save test case</strong>.
      <img
        src="/assets/images/help/classroom/assignments-click-save-test-case-button.png"
        alt="“Save test case” button for an autograding test"
      />
      - To edit a test, to the right of the test name, click {% octicon “pencil”
      aria-label=“The pencil icon” %}.
      <img
        src="/assets/images/help/classroom/autograding-click-pencil.png"
        alt="Pencil icon for editing an autograding test"
      />
      Configure the test, then click <strong>Save test case</strong>.
      <img
        src="/assets/images/help/classroom/assignments-click-save-test-case-button.png"
        alt="“Save test case” button for an autograding test"
      />
      - To delete a test, to the right of the test name, click {% octicon
      “trash” aria-label=“The trash icon” %}.
      <img
        src="/assets/images/help/classroom/autograding-click-trash.png"
        alt="Trash icon for deleting an autograding test"
      />
      1. At the bottom of the page, click <strong>Update assignment</strong>.
      <img
        src="/assets/images/help/classroom/assignments-click-update-assignment.png"
        alt="“Update assignment” button at the bottom of the page"
      />
    </p>
    <h2 id="viewing-logs-from-autograding-tests">
      Viewing logs from autograding tests
    </h2>
    <p>
      {% data reusables.classroom.sign-into-github-classroom %} {% data
      reusables.classroom.click-classroom-in-list %} {% data
      reusables.classroom.click-assignment-in-list %} 1. To the right of a
      submission, click <strong>View test</strong>.
      <img
        src="/assets/images/help/classroom/assignments-click-view-test.png"
        alt="“View test” button for an assignment submission"
      />
      1. Review the test output. For more information, see “<a
        href="/actions/managing-workflow-runs/using-workflow-run-logs"
        >Using workflow run logs</a
      >.”
    </p>
    <h2 id="further-reading">Further reading</h2>
    <ul>
      <li>
        <a href="/actions"
          >{% data variables.product.prodname_actions %} documentation</a
        >
      </li>
    </ul>
  </body>
</html>
